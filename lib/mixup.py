import torchvision.transforms.functional as F
import numpy as np
import torch
import cv2
from utils import draw_rect, get_info_bbox

class Mixup(object):
    def __init__(self, lambd=0.3):
        """
        Initialize the Mixup data augmentation object.

        Args:
            lambd (float): The mixing factor (lambda) that determines the degree of mixing between the two images.
        """
        self.lambd = lambd
        
    def __call__(self, img1, bboxes1, img2, bboxes2):
        """
        Mix two images and their associated bounding boxes based on the given mixing factor.

        Args:
            img1 (numpy.ndarray or PIL.Image): The first input image.
            bboxes1 (numpy.ndarray): Bounding boxes associated with the first image.
            img2 (numpy.ndarray or PIL.Image): The second input image.
            bboxes2 (numpy.ndarray): Bounding boxes associated with the second image.

        Returns:
            numpy.ndarray: The mixed image generated by blending the two input images based on the lambda factor.
            numpy.ndarray: The mixed bounding boxes, concatenated from both input bounding boxes.
        """
        # Convert the input images to PyTorch tensors
        img1 = F.to_tensor(img1)
        img2 = F.to_tensor(img2)
        
        # Determine the dimensions of the mixed image
        mixup_width = max(img1.shape[2], img2.shape[2])
        mixup_height = max(img1.shape[1], img2.shape[1])
        
        # Create an empty tensor to hold the mixed image
        mix_img = torch.zeros(3, mixup_height, mixup_width)
        
        # Apply mixing to the images based on the lambda factor
        mix_img[:, :img1.shape[1], :img1.shape[2]] = img1 * self.lambd
        mix_img[:, :img2.shape[1], :img2.shape[2]] += img2 * (1. - self.lambd)
        
        # Convert the mixed image tensor back to a PIL image and then to a NumPy array
        img = F.to_pil_image(mix_img)
        img = np.array(img)[:, :, ::-1].copy()
        
        # Concatenate the bounding boxes from both images
        mix_bboxes = np.concatenate((bboxes1, bboxes2))
    
        # Return the mixed image and mixed bounding boxes
        return img, mix_bboxes

    
def main():
    label_mapping = {
        'disc': 0,
        'adapter':1,
        'guide':2,
        'qr':3,
        'gun':4,
        'boom': 5,
        'head': 6,
    }
    
    path_img = 'D:/data-augmentation-for-object-detection/data/1a7ff59a026f50acbf91d546e8048637.jpg'
    img = cv2.imread(path_img)
    path_xml = 'D:/data-augmentation-for-object-detection/data/1a7ff59a026f50acbf91d546e8048637.xml'
    bboxes = get_info_bbox(path_xml, label_mapping)
    
    path_img2 = 'D:/data-augmentation-for-object-detection/data/1a7a62de1bd9edc8e7382e33d81f069a.jpg'
    img2 = cv2.imread(path_img2)
    path_xml2 = 'D:/data-augmentation-for-object-detection/data/1a7a62de1bd9edc8e7382e33d81f069a.xml'
    bboxes2 = get_info_bbox(path_xml2, label_mapping)
    
    
    
    img_res, bboxes_res = Mixup(0.5)(img.copy(), bboxes.copy(), img2.copy(), bboxes2.copy())
    draw_rect(img_res, bboxes_res, img)
    
if __name__ == '__main__':
    main()